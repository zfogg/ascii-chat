name: 'Publish Test Results'
description: 'Validates JUnit XML, publishes test results to GitHub, uploads to Codecov'
inputs:
  test-type:
    description: 'Type of test (unit, integration, performance)'
    required: true
  os-name:
    description: 'Operating system name (ubuntu, macos)'
    required: true
  build-type:
    description: 'Build type (debug, release, or empty for integration/perf tests)'
    required: false
    default: ''
  junit-file:
    description: 'Path to JUnit XML file'
    required: false
    default: 'junit.xml'
  coverage-files:
    description: 'Coverage file pattern for Codecov'
    required: false
    default: './*.gcov'
  codecov-token:
    description: 'Codecov token'
    required: true
  upload-coverage:
    description: 'Whether to upload coverage to Codecov'
    required: false
    default: 'false'

runs:
  using: "composite"
  steps:
    # Validate codecov.yml configuration
    - name: Validate Codecov Configuration
      shell: bash
      run: |
        if [ -f "codecov.yml" ]; then
          echo "üîç Validating codecov.yml configuration..."
          response=$(curl -s --data-binary @codecov.yml https://codecov.io/validate)
          if echo "$response" | grep -q '"valid": true'; then
            echo "‚úÖ codecov.yml is valid"
          else
            echo "‚ùå codecov.yml validation failed:"
            echo "$response" | jq . || echo "$response"
            exit 1
          fi
        else
          echo "‚ö†Ô∏è No codecov.yml found, skipping validation"
        fi

    # Validate JUnit XML exists and is valid
    - name: Validate JUnit XML
      if: always()
      shell: bash
      run: |
        if [ -f "${{ inputs.junit-file }}" ]; then
          echo "‚úÖ JUnit XML exists ($(wc -l < ${{ inputs.junit-file }}) lines)"
          xmllint --format "${{ inputs.junit-file }}" > /dev/null && echo "‚úÖ Valid XML" || echo "‚ùå Invalid XML"
        else
          echo "‚ùå JUnit XML not found at ${{ inputs.junit-file }}"
          echo "Looking for XML files:"
          find . -name "*.xml" -type f | head -5
        fi

    # Publish test results to GitHub checks
    - name: Publish Test Results to GitHub
      uses: EnricoMi/publish-unit-test-result-action@v2
      if: always()
      with:
        files: |
          ${{ inputs.junit-file }}
        check_name: |
          ${{ inputs.test-type == 'unit' && format('{0} Tests ({1}-{2})', 'Unit', inputs.os-name, inputs.build-type) || 
              inputs.test-type == 'integration' && format('{0} Tests ({1})', 'Integration', inputs.os-name) ||
              format('{0} Tests ({1})', 'Performance', inputs.os-name) }}
        comment_title: |
          ${{ inputs.test-type == 'unit' && format('{0} Test Results ({1}-{2})', 'Unit', inputs.os-name, inputs.build-type) || 
              inputs.test-type == 'integration' && format('{0} Test Results ({1})', 'Integration', inputs.os-name) ||
              format('{0} Test Results ({1})', 'Performance', inputs.os-name) }}
        compare_to_earlier_commit: true
        test_changes_limit: 10
        fail_on: 'nothing'  # Don't fail the workflow based on test results

    # Upload test results to Codecov
    - name: Upload Test Results to Codecov
      if: ${{ always() && hashFiles(inputs.junit-file) != '' }}
      uses: codecov/test-results-action@v1
      with:
        files: ${{ inputs.junit-file }}
        flags: |
          ${{ inputs.test-type == 'unit' && format('ascii-chat-tests-{0}-{1}', inputs.os-name, inputs.build-type) || 
              inputs.test-type == 'integration' && format('ascii-chat-integration-{0}', inputs.os-name) ||
              format('ascii-chat-performance-{0}', inputs.os-name) }}
        token: ${{ inputs.codecov-token }}
        fail_ci_if_error: false

    # Upload coverage to Codecov (optional)
    - name: Upload Coverage to Codecov
      if: ${{ always() && inputs.upload-coverage == 'true' }}
      uses: codecov/codecov-action@v4
      with:
        token: ${{ inputs.codecov-token }}
        files: ${{ inputs.coverage-files }}
        directory: .
        flags: |
          ${{ inputs.test-type == 'unit' && format('ascii-chat-tests-{0}-{1}', inputs.os-name, inputs.build-type) || 
              inputs.test-type == 'integration' && format('ascii-chat-integration-{0}', inputs.os-name) ||
              format('ascii-chat-performance-{0}', inputs.os-name) }}
        name: |
          ${{ inputs.test-type == 'unit' && format('ascii-chat-coverage-{0}-{1}', inputs.os-name, inputs.build-type) || 
              inputs.test-type == 'integration' && format('ascii-chat-integration-coverage-{0}', inputs.os-name) ||
              format('ascii-chat-performance-coverage-{0}', inputs.os-name) }}
        fail_ci_if_error: false
        verbose: true